{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88467d31-3a96-4fec-ad13-1357c8227597",
   "metadata": {},
   "source": [
    "# Lab 7: Deep Learning with TensorFlow - Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10aa0f8-4589-4916-ab85-49cfa5574844",
   "metadata": {},
   "source": [
    "## Dataset: Wine Quality Dataset (for Classification)\n",
    "\n",
    "Description:\n",
    "The Wine Quality Dataset is a popular dataset for classification tasks. It contains information about the quality of red and white wines based on various chemical properties like alcohol, acidity, sugar content, and pH. The goal is to predict the quality of wine (as a discrete value from 0 to 10, though it's typically grouped into good/bad quality classes for simplicity).\n",
    "\n",
    "#### Why This Dataset?\n",
    "This dataset has 1599 samples, which is large enough for deep learning. Unlike smaller datasets (such as the Iris dataset), it provides a variety of features that will allow the deep neural network to learn non-linear relationships, which is crucial for deep learning models.\n",
    "\n",
    "TensorFlow is a powerful and flexible deep learning framework that is well-suited for handling large, complex datasets. While scikit-learn is an excellent tool for simpler machine learning tasks, TensorFlow provides a range of advanced features that are particularly useful for deep learning applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f145aa1-3c5b-470b-844a-66269ddee88a",
   "metadata": {},
   "source": [
    "### Lab Objective:\n",
    "In this lab, you will:\n",
    "\n",
    "- Use **TensorFlow** to train a simple deep learning model for multiclass classification.\n",
    "- Understand how **RandomSearch or GridSearch** can be used for hyperparameter tuning.\n",
    "- Apply **regularisation** techniques (Dropout and L2 regularisation) to avoid overfitting.\n",
    "- Compare the performance of your model before and after tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ea46f2-8e5a-4d95-b74b-d7ff48a4d75a",
   "metadata": {},
   "source": [
    "#### Importing Libraries and Dataset\n",
    "First, we will import the necessary libraries and load the Wine Quality dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da4f19-3b5e-4bc0-8372-6106ab62a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d30e40-0f2d-41b5-802e-0de8053689fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f33f7ff-2163-4da2-a809-5efb61fd04d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from keras.metrics import Precision, Recall, AUC\n",
    "\n",
    "#from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Setup Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c4c261-524b-4012-97fb-879422340d74",
   "metadata": {},
   "source": [
    "Next, let's load the Wine Quality dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d9a1ee-6289-4b0e-a100-d734092887a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9aa5ab-e1e7-41c2-ab0b-7034fc3ab977",
   "metadata": {},
   "source": [
    "#### Standardise Data\n",
    "Next, let's scale the data. Neural networks perform better when the features are on similar scales.\n",
    "Use `StandardScaler` from `sklearn` to scale your data. Apply it on both the training and testing data.\n",
    "\n",
    "Why do you think normalising/standardising the data is important for neural networks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f2ccd9-fd10-489b-a85c-0b9ee276469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d2cd02-63fe-461f-9a3f-71826bd0776c",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002924a8-0dff-4b8e-bb7b-1d5a3c746abc",
   "metadata": {},
   "source": [
    "#### Build the Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da789e4-17e2-48bb-b5b1-49235516ff50",
   "metadata": {},
   "source": [
    "We will now build a simple neural network with four hidden layers.\n",
    "\n",
    "Define a simple feedforward neural network using **TensorFlow's** Sequential model, the model should include:\n",
    "\n",
    "- Four hidden layer each with 64 neurons and ReLU activation.\n",
    "\n",
    "- An output layer with 3 neurons (as we have 3 classes) and Softmax activation function.\n",
    "\n",
    "Why are we using ReLU activation in the hidden layers and Softmax in the output layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cd26f6-a04c-4233-9d6d-9fe91e5abebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model = tf.keras.models.Sequential([\n",
    "\n",
    "    \n",
    "])\n",
    "\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb600254-1ebf-4c79-934a-aba6909ec292",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7954afae-e229-4fdd-926f-86c615e75996",
   "metadata": {},
   "source": [
    "#### Compile and Train the Model\n",
    "\n",
    "Compile then train the model for 20 epochs using `model.fit()`. Set the batch size to 32 and use 20% of the data as a validation set to monitor performance.\n",
    "\n",
    "What do you think will happen if you train the model for too few epochs? And what if you train it for too many epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76de9e78-ea75-435d-9928-22bdc4e1dd94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b042fda8-e2a6-48af-aa1e-4c39b92eb142",
   "metadata": {},
   "source": [
    "Answer: Training for too few epochs may lead to underfitting, where the model does not learn enough from the data. Training for too many epochs can lead to overfitting, where the model learns the training data too well, including noise, and performs poorly on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0482c62-1f38-40af-9e02-56430ae4aa7a",
   "metadata": {},
   "source": [
    "#### Evaluate the Model\n",
    "Evaluate the modelâ€™s performance on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d058a2df-bafa-48c3-94e6-1e89fe3c142f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca7d7b3a-b7fa-4da7-96d0-f807fa4d4a2d",
   "metadata": {},
   "source": [
    "Convert predictions from probabilities to class labels, use `np.argmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6081dc2-bd4c-49c7-b85b-f294aebd9f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32716a11-5ef0-4a5f-9980-50d5272e460f",
   "metadata": {},
   "source": [
    "Generate classification report \n",
    "To evaluate the performance of your model beyond just accuracy, you can use multiple evaluation metrics such as precision, recall, and F1-score for each class. These metrics give a more detailed understanding of how well the model performs for each individual class, especially in cases where the classes are imbalanced.\n",
    "\n",
    "Use `classification_report` from `sklearn` to evaluate the model after training. This will provide a detailed report that includes precision, recall, F1-score, and support for each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68673e12-fcbf-481c-80c3-9cb4c64f94df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce27d92c-75e3-4032-8e49-fee2bdb463fc",
   "metadata": {},
   "source": [
    "Result explanation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608beaea-a254-408d-8e3e-7419e783d136",
   "metadata": {},
   "source": [
    "#### Apply Regularisation Techniques\n",
    "\n",
    "Update your model to include:\n",
    "\n",
    "- `Dropout` with a 20% drop rate after the first hidden layer.\n",
    "\n",
    "- `L2 regularisation` on the weights in the first hidden layer.\n",
    "\n",
    "Why do you think adding `Dropout` and `L2 regularisation` can help improve model generalisation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f497ae11-ccb7-4d01-9443-460d9c59ae3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f22c6e8b-6c1e-4315-a053-51f1e8399706",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b538f1ca-cd25-4366-a0d5-509a754587d7",
   "metadata": {},
   "source": [
    "Now create and train regularised model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a851b016-5fde-4df6-974e-9bb2166791aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3162c394-2e24-4623-9ad1-48a6d596facc",
   "metadata": {},
   "source": [
    "Now predict on regularised model and see if you can spot any improvement in model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a189ad-b6b0-424a-8d24-56753a983c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c79d226-6d83-4f90-908b-3a492fb280bf",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning with RandomizedSearch/GridSearchCV\n",
    "Use `RandomizedSearch` or `GridSearchCV` to tune the batch size and number of epochs. Set the following options for the hyperparameter grid:\n",
    "\n",
    "- Batch size: [16, 32]\n",
    "\n",
    "- Epochs: [10, 20]\n",
    "\n",
    "- Optimizer: [adam, sgd]\n",
    "\n",
    "The batch size and number of epochs are chosen to balance model training efficiency and performance. A smaller batch size (16) allows more frequent updates, potentially improving model generalisation, while a larger batch size (32) may speed up training. The range of epochs (10-20) ensures adequate model training without excessive overfitting or underfitting. Additionally, using both Adam and SGD optimisers provides flexibility to test different optimization strategies and improve model convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9eb408-3f83-43f9-8b0f-f2fcd795d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom estimator to work with RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6161176a-9ffb-47b5-8d39-b246e838da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the KerasModel (custom estimator that works with RandomizedSearchCV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730ec174-3794-445e-9304-53eb6da95027",
   "metadata": {},
   "source": [
    "##### Now train the model with the best parameters then predict and evaluate trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8348c127-0b17-4d33-ba04-5cf6cb49f701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
